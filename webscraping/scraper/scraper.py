from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import requests
import logging
from scraper.parser import *
from scraper.utils import *

class Scrap_Selenium:

    def __init__(self, url):
        options = Options()
        # options.add_argument("--headless")  
        # options.add_argument("--disable-gpu")
        # options.add_argument("--no-sandbox")
        # options.add_argument("--window-size=1920,1080")

        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
        self.driver.get(url)

        # Intentar aceptar las cookies (modifica el XPATH seg√∫n la web)
        try:
            cookie_button = WebDriverWait(self.driver, 5).until(
                    EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), "Aceptar")]'))
            )
            cookie_button.click()
            print("‚úÖ Cookies aceptadas correctamente")
        except Exception as e:
            print("‚ö† No se encontr√≥ el bot√≥n de cookies o ya estaban aceptadas:", e)

        self.page = 1

    def fetch_html_selenium(self):
        '''Devuelve el HTML actual de la p√°gina.'''
        return self.driver.page_source
        
    def scrape(self, output_file):
        '''Ejecuta el proceso de scarping'''
        print(f"üåç Extrayendo datos de: {self.driver.current_url}")
        html = self.fetch_html_selenium()

        # Diccionario de parsers por palabra clave en el nombre del archivo
        parsers = {
            'mercado': parse_data_ml,
            'switch': parse_data_switch,
            'alibaba': parse_data_alibaba
        }

        # Buscar el parser adecuado seg√∫n el nombre del archivo
        parse_function = None
        for keyword, func in parsers.items():
            if keyword in output_file.lower(): # Ignora may√∫sculas/min√∫sculas
                parse_function = func
                break # Salir del bucle al encontrar el primer match
        
        if parse_function:
            # print(f"üìÑ Longitud del HTML: {len(html)} caracteres")
            # print(f"üîç Vista previa HTML:\n{html[:1000]}")  # Muestra los primeros 500 caracteres
            data = parse_function(html)
            save_to_csv(data, output_file)
        else:
            print(f'No se encontr√≥ un parser para el archivo {output_file}.')

    def next_button(self, output_file):
        '''Hace clic en el bot√≥n "Siguiente" si est√° disponible'''
        buttons = {
            'mercado': '//a[@title="Siguiente"]',
            'switch': '//a[@title="Siguiente"]',
            'alibaba': '//a[@aria-label="Go to next page"]'
        }
        link_button = ''
        for keyword, link in buttons.items():
            if keyword in output_file.lower():
                link_button = link
                break
        
        try:
            current_url = self.driver.current_url  # Guardar la URL actual antes de hacer clic
            next_button = WebDriverWait(self.driver, 5).until(
                EC.element_to_be_clickable((By.XPATH, link_button))
            )
            next_button.click()

            # Esperar hasta que la URL cambie (si cambia)
            WebDriverWait(self.driver, 10).until(
                lambda driver: driver.current_url != current_url
            )

            # Esperar que la nueva p√°gina cargue antes de continuar
            # WebDriverWait(self.driver, 5).until(
            #     EC.staleness_of(next_button)
            # )

            self.page += 1
            print(f"‚û° Avanzando a la p√°gina {self.page}")
            return True
        except Exception as e:
            print("üö´ No hay m√°s p√°ginas o ocurri√≥ un error:", e)
            return False
    
    def close(self):
        '''Cierra el navegador'''
        self.driver.quit()



if __name__ == '__main__':
    url = 'https://listado.mercadolibre.com.pe/incubadora-huevo-codorniz'
    url2 = 'https://listado.mercadolibre.com.pe/nintendo-switch#D[A:nintendo%20switch]'
    output_file = 'mercado_libre.csv'
    scrap_selenium = Scrap_Selenium(url)
    

    while True:
        try:
            html = scrap_selenium.fetch_html_selenium()
            data = parse_data_ml(html)
            save_to_csv(data, output_file)
            print(data)

            try:
                # Esperar a que aparezca el banner de cookies
                cookie_button = WebDriverWait(scrap_selenium.driver, 5).until(
                    EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), "Aceptar")]'))
                )
                cookie_button.click()
                print("Banner de cookies cerrado.")
            except:
                print("No se encontr√≥ el banner de cookies o ya est√° cerrado.")

            # Esperar que el not√≥n "Siguiente" est√© disponible
            next_button = WebDriverWait(scrap_selenium.driver, 5).until(
                EC.element_to_be_clickable((By.XPATH, '//a[@title="Siguiente"]'))
            )
            next_button.click()

            # Esperar que la nueva p√°gina cargue antes de continuar
            WebDriverWait(scrap_selenium.driver, 5).until(
                EC.staleness_of(next_button) # Espera a que el bot√≥n se 'refresque'
            )
        except Exception as e:
            print('No hay m√°s p√°ginas disponibles o ocurri√≥ un error:', e)
            break # Sale del bucle cuando no hay m√°s botones
    
    scrap_selenium.driver.quit()
